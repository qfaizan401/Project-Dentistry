{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg       \n",
    "import matplotlib.pyplot as plt        \n",
    "import matplotlib.patches as mpatches \n",
    "from skimage import measure         \n",
    "import scipy.ndimage as ndi  \n",
    "from os.path import exists, join\n",
    "from os import listdir\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample_data/images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-88e2c8df9f5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_data/images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_data/images'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "images = os.listdir('sample_data/images')\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_img (img_file):\n",
    "    img_dir = 'sample_data/images'\n",
    "#     user_input = input('Enter file name')\n",
    "    if os.path.exists(img_file):\n",
    "        img = io.imread(img_file)\n",
    "        return img\n",
    "    else:\n",
    "        return f'file not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'sample_data/images'\n",
    "user_input = input('Enter file name : ')\n",
    "\n",
    "img_file_path = os.path.join(img_dir, user_input)\n",
    "img = input_img(img_file_path)\n",
    "io.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage.exposure import histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# image_path = img\n",
    "def loadImages(img):\n",
    "    '''Put files into lists and return them as one list with all images \n",
    "     in the folder'''\n",
    "    image_files = sorted([os.path.join(path, 'train', file)\n",
    "                          for file in os.listdir(path + \"/train\")\n",
    "                          if file.endswith('.png')])\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image\n",
    "def display_one(img, title1 = \"Original\"):\n",
    "    plt.imshow(img), plt.title(title1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def processing(data):\n",
    "    \n",
    "    # Reading 3 images to work\n",
    "    img = [cv2.imread(i, cv2.IMREAD_UNCHANGED) for i in data[:3]]\n",
    "    try:\n",
    "        print('Original size',img[0].shape)\n",
    "    except AttributeError:\n",
    "        print(\"shape not found\")\n",
    "   \n",
    "    # --------------------------------\n",
    "    # setting dim of the resize\n",
    "    height = 220\n",
    "    width = 220\n",
    "    dim = (width, height)\n",
    "    res_img = []\n",
    "    for i in range(len(img)):\n",
    "        res = cv2.resize(img[i], dim, interpolation=cv2.INTER_LINEAR)\n",
    "        res_img.append(res)\n",
    "\n",
    "    # Checcking the size\n",
    "    try:\n",
    "        print('RESIZED', res_img[1].shape)\n",
    "    except AttributeError:\n",
    "        print(\"shape not found\")\n",
    "    \n",
    "    \n",
    "    # Visualizing one of the images in the array\n",
    "    original = res_img[1]\n",
    "    display_one(original)\n",
    "    # ----------------------------------\n",
    "    # Remove noise\n",
    "    # Using Gaussian Blur\n",
    "    no_noise = []\n",
    "    for i in range(len(res_img)):\n",
    "        blur = cv2.GaussianBlur(res_img[i], (5, 5), 0)\n",
    "        no_noise.append(blur)\n",
    "\n",
    "\n",
    "    image = no_noise[1]\n",
    "    display(original, image, 'Original', 'Blured')\n",
    "    #---------------------------------\n",
    "    # Segmentation\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Displaying segmented images\n",
    "    display(original, thresh, 'Original', 'Segmented')\n",
    "    # Further noise removal (Morphology)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    #Displaying segmented back ground\n",
    "    display(original, sure_bg, 'Original', 'Segmented Background')\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    markers = cv2.watershed(image, markers)\n",
    "    image[markers == -1] = [255, 0, 0]\n",
    "\n",
    "    # Displaying markers on the image\n",
    "    display(original, markers, 'Original', 'Marked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # calling global variable\n",
    "    global image_path\n",
    "    '''The var Dataset is a list with all images in the folder '''\n",
    "    dataset = loadImages(image_path)\n",
    "    print('number of FILES in dir', len(dataset))\n",
    "    print(\"--------------------------------\")\n",
    "    print(cv2.imread(dataset[0]).shape)\n",
    "    print(\"List of files the first 3 in the folder:\\n\",dataset[:3])\n",
    "    print(\"--------------------------------\")\n",
    "    \n",
    "    # sending all the images to pre-processing\n",
    "    processing(dataset)\n",
    "   \n",
    "    #list files in directory\n",
    "    #a = tf.gfile.ListDirectory('drive/My Drive/BiSeNet/dataset/train')\n",
    "    #print(a)\n",
    "  \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
